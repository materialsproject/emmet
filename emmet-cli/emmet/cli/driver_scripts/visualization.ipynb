{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from maggma.stores.advanced_stores import MongograntStore\n",
    "from maggma.stores.advanced_stores import Sort\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date, datetime\n",
    "from monty.json import MontyDecoder\n",
    "from datetime import timedelta\n",
    "# configuration stuff\n",
    "from sys import platform\n",
    "import maggma\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    import plotly.io as pio\n",
    "    pio.orca.config.use_xvfb = True\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer = \"notebook\" # change to pdf for live viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdrive_mongo_store = MongograntStore(mongogrant_spec=\"rw:knowhere.lbl.gov/mp_core_mwu\",\n",
    "                                         collection_name=\"gdrive\")\n",
    "gdrive_mongo_store.connect()\n",
    "\n",
    "tasks_mongo_store = MongograntStore(mongogrant_spec=\"ro:mongodb04.nersc.gov/mp_emmet_prod\",\n",
    "                                        collection_name=\"tasks\")\n",
    "tasks_mongo_store.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"title\"] = np.array([\"Total in Gdrive\", \"Total Tasks\"])\n",
    "df[\"count\"] = np.array([gdrive_mongo_store.count(), tasks_mongo_store.count()])\n",
    "fig = px.pie(df, values='count', names='title', title=\"Tasks & GDrive\")\n",
    "fig.show(renderer=renderer)\n",
    "\n",
    "print(\"WARNING: This Pie chart might not reflect the actual progress since there are tasks that belong to an deprecated material\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"type\"] = np.array([\"Total in Gdrive\",\"Total in NOMAD\" ])\n",
    "df[\"count\"] = np.array([gdrive_mongo_store.count(criteria={\"error\": {\"$eq\": None}}), \n",
    "                        gdrive_mongo_store.count(criteria={\"nomad_updated\": {\"$ne\": None}})])\n",
    "fig = px.bar(df,\n",
    "             x=\"type\",\n",
    "             y=\"count\", title=\"Num uploaded to Gdrive and NOMAD\", color=\"type\")\n",
    "fig.show(renderer=renderer)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_content_gdrive = gdrive_mongo_store.query(criteria={\"error\": None},properties={\"file_size\":1})\n",
    "gdrive_size = 0\n",
    "for c in all_content_gdrive:\n",
    "    gdrive_size += c[\"file_size\"]\n",
    "print(f\"GDrive: {gdrive_size} bytes = {gdrive_size*1e-6} mb = {gdrive_size*1e-9} gb\")\n",
    "\n",
    "\n",
    "all_content_nomad = gdrive_mongo_store.query(criteria={\"$and\": \n",
    "                                                       [{\"error\": None}, \n",
    "                                                        {\"nomad_updated\": {\"$ne\":None}}]\n",
    "                                                      },\n",
    "                                             properties={\"file_size\":1})\n",
    "nomad_size = 0\n",
    "for c in all_content_nomad:\n",
    "    nomad_size += c[\"file_size\"]\n",
    "print(f\"Nomad: {nomad_size} bytes = {nomad_size*1e-6} mb = {nomad_size*1e-9} gb\")\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"title\"] = np.array([\"GDrive Upload GB\",\"Nomad Upload GB\" ])\n",
    "df[\"bytes\"] = np.array([gdrive_size*1e-9, nomad_size*1e-9])\n",
    "fig = px.bar(df, y='bytes', x='title', color='title', title=\"GDrive & NOMAD by bytes\")\n",
    "fig.show(renderer=renderer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"title\"] = np.array([\"Success\",\"Failed\" ])\n",
    "df[\"count\"] = np.array([gdrive_mongo_store.count(criteria={\"error\": {\"$eq\": None}}), \n",
    "                        gdrive_mongo_store.count(criteria={\"error\": {\"$ne\": None}})])\n",
    "fig = px.pie(df, values='count', names='title', title=\"GDrive Upload Status\")\n",
    "fig.show(renderer=renderer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dates_btw(start_dt, end_dt):\n",
    "    \"\"\"\n",
    "    find the number of dates between start date and end date\n",
    "    \"\"\"\n",
    "    def daterange(date1, date2):\n",
    "        if date1 is None: date1 = date2\n",
    "        if date2 is None: date2 = date1\n",
    "        for n in range(int((date2 - date1).days)+1):\n",
    "            yield date1 + timedelta(n)\n",
    "    dates = []\n",
    "    for dt in daterange(start_dt, end_dt+timedelta(days=1)):\n",
    "        date_format = dt.date()\n",
    "        dates.append(datetime(date_format.year, date_format.month, date_format.day))\n",
    "    return dates\n",
    "\n",
    "def find_earliest_date(store, field):\n",
    "    \"\"\"\n",
    "    find the earliest record date\n",
    "    \"\"\"\n",
    "    return list(store.query(criteria={\"error\": {\"$eq\": None}}, sort={field:maggma.core.store.Sort.Ascending}, limit=1))[0][field]\n",
    "\n",
    "def find_latest_date(store, field):\n",
    "    \"\"\"\n",
    "    find the latest_record date\n",
    "    \"\"\"\n",
    "    return list(store.query(criteria={\"error\": {\"$eq\": None}}, sort={field:maggma.core.store.Sort.Descending}, limit=1))[0][field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_time_series_data(field_name):\n",
    "    \"\"\"\n",
    "    Find all time series data for that field, put them in buckets of dates.\n",
    "    \"\"\"\n",
    "    dates = find_dates_btw(find_earliest_date(gdrive_mongo_store, field_name), \n",
    "                           find_latest_date(gdrive_mongo_store, field_name))\n",
    "    # last_updated \n",
    "    result = dict()\n",
    "    for i in range(len(dates)):\n",
    "        if i == 0:\n",
    "            result[dates[i]] = 0\n",
    "        else:\n",
    "            c = gdrive_mongo_store.count(criteria={field_name: {\"$lte\": dates[i]}})\n",
    "            result[dates[i]] = c\n",
    "    return result\n",
    "def make_time_series_data_nomad(field_name=\"nomad_updated\"):\n",
    "    \"\"\"\n",
    "    Find all time series data for that field, put them in buckets of dates.\n",
    "    \"\"\"\n",
    "    start = list(gdrive_mongo_store.query(criteria={field_name: {\"$ne\": None}}, \n",
    "                                            sort={field_name:maggma.core.store.Sort.Ascending}, limit=1))[0][field_name]\n",
    "    \n",
    "    end = list(gdrive_mongo_store.query(criteria={field_name: {\"$ne\": None}}, \n",
    "                                        sort={field_name:maggma.core.store.Sort.Descending}, limit=1))[0][field_name]\n",
    "    dates = find_dates_btw(start, end)\n",
    "    # last_updated \n",
    "    result = dict()\n",
    "    for i in range(len(dates)):\n",
    "        if i == 0:\n",
    "            result[dates[i]] = 0\n",
    "        else:\n",
    "            c = gdrive_mongo_store.count(criteria={field_name: {\"$lte\": dates[i]}})\n",
    "            result[dates[i]] = c\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_updated_data = make_time_series_data(\"last_updated\")\n",
    "nomad_updated_data = make_time_series_data_nomad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = set(last_updated_data.keys()).union(set(nomad_updated_data.keys()))\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=list(last_updated_data.keys()), y=list(last_updated_data.values()),\n",
    "                    mode='lines+markers',\n",
    "                    name='last_updated'))\n",
    "fig.add_trace(go.Scatter(x=list(nomad_updated_data.keys()), y=list(nomad_updated_data.values()),\n",
    "                    mode='lines+markers',\n",
    "                    name='nomad_updated'))\n",
    "\n",
    "# add features\n",
    "fig.update_layout(\n",
    "    title=\"GDrive Upload Status\",\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"# Submission\",\n",
    "    font=dict(\n",
    "        family=\"Franklin Gothic\",\n",
    "        size=14,\n",
    "        color=\"#0d0d0d\"\n",
    "    ),   \n",
    "    yaxis_type=\"log\",\n",
    ")\n",
    "fig.show(renderer=renderer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
